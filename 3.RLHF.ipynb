{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF llama2 7b using SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U sagemaker boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "SM_TRAIN_DIR = \"/opt/ml/input/data\" \n",
    "\n",
    "hyperparameters[\"actor_model_name_or_path\"] = \"/opt/ml/input/data/sft\"\n",
    "hyperparameters[\"critic_model_name_or_path\"] = \"/opt/ml/input/data/reward\"\n",
    "hyperparameters[\"output_dir\"] =  \"/opt/ml/model\"\n",
    "hyperparameters[\"data_path\"] = \"Dahoas/rm-static\"\n",
    "hyperparameters[\"data_split\"] = \"2,4,4\"\n",
    "hyperparameters[\"num_padding_at_beginning\"] = 1\n",
    "hyperparameters[\"per_device_generation_batch_size\"] = 1\n",
    "hyperparameters[\"per_device_training_batch_size\"] = 1\n",
    "#hyperparameters[\"num_padding_at_beginning\"] = 0\n",
    "hyperparameters[\"generation_batches\"] = 1\n",
    "hyperparameters[\"ppo_epochs\"] = 1\n",
    "hyperparameters[\"max_answer_seq_len\"] = 256\n",
    "hyperparameters[\"max_prompt_seq_len\"] = 256\n",
    "hyperparameters[\"actor_learning_rate\"] = 9.65e-6\n",
    "hyperparameters[\"critic_learning_rate\"] = 5e-6\n",
    "hyperparameters[\"actor_weight_decay\"] = 0.1\n",
    "hyperparameters[\"critic_weight_decay\"] = 0.1\n",
    "hyperparameters[\"num_train_epochs\"] = 1\n",
    "hyperparameters[\"lr_scheduler_type\"] = \"cosine\"\n",
    "hyperparameters[\"gradient_accumulation_steps\"] = 1\n",
    "hyperparameters[\"actor_gradient_checkpointing\"] = \"\"\n",
    "\n",
    "hyperparameters[\"critic_gradient_checkpointing\"] = \"\"\n",
    "hyperparameters[\"offload_reference_model\"] = \"\"\n",
    "hyperparameters[\"disable_actor_dropout\"] = \"\"\n",
    "hyperparameters[\"deepspeed\"] = \"\"\n",
    "\n",
    "hyperparameters[\"actor_zero_stage\"] = 3\n",
    "hyperparameters[\"critic_zero_stage\"] = 3\n",
    "hyperparameters[\"enable_hybrid_engine\"] = \"\"\n",
    "\n",
    "#hyperparameters[\"enable_mixed_precision_lora\"] = \"\"\n",
    "#hyperparameters[\"actor_lora_dim\"] = 64\n",
    "#hyperparameters[\"critic_lora_dim\"] = 64\n",
    "#hyperparameters[\"critic_lora_module_name\"] = \"layers.\"\n",
    "#hyperparameters[\"actor_lora_module_name\"] = \"layers.\"\n",
    "\n",
    "#hyperparameters[\"dtype\"] = \"bf16\"\n",
    "\n",
    "hyperparameters[\"output_dir\"] = \"/opt/ml/model\"\n",
    "\n",
    "\n",
    "hyperparameters[\"access_token\"] = \"hf_XXXXX\" # Replace the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {}\n",
    "env['FI_PROVIDER'] = 'efa'\n",
    "env['NCCL_PROTO'] = 'simple'\n",
    "env['FI_EFA_USE_DEVICE_RDMA'] = '1'\n",
    "env['RDMAV_FORK_SAFE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = \"llama7b-rlhf-dschat\"\n",
    "estimator = PyTorch(\n",
    "    base_job_name=base_job_name,\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"rlhf/main.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.13.1\",\n",
    "    py_version=\"py39\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    disable_profiler=True,\n",
    "    environment=env,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    keep_alive_period_in_seconds=600, \n",
    "    disable_output_compression=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_model_path = \"<path to model from step 1 sft>\"\n",
    "critic_model_path = \"<path to model from step 2 reward>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"sft\":actor_model_path,\"reward\":critic_model_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.update_training_job(estimator.latest_training_job.job_name, resource_config={\"KeepAlivePeriodInSeconds\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
